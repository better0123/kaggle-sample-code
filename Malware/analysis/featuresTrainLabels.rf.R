# rf.R
#
# Runs a random forest for feature selection 
#

library('randomForest')

FEATURES_FILE  <- "/home/chefele/kaggle/Malware/analysis/featuresTrainLabels.csv"
LABELS_FILE    <- "/home/chefele/kaggle/Malware/download/trainLabels.csv"

NTREE          <- 500
TREE_NODE_SIZE <- 20
RND_SEED       <- 4242
set.seed(RND_SEED)

id.features <- read.csv(FEATURES_FILE)
id.labels   <- read.csv(LABELS_FILE)

features <- merge(id.features, id.labels, by="Id")
labels   <- as.factor(features$Class)
labels.int <- features$Class
features$Class <- NULL
features$Id    <- NULL

features$Rand <- runif(nrow(features))

print(head(id.features))
print(head(id.labels))
print(head(features))
print(head(labels))
print(head(labels.int))

rf <- randomForest( features, labels, 
                    ntree=NTREE, nodesize=TREE_NODE_SIZE, 
                    importance=TRUE, do.trace=TRUE) 

print("ERRORS")
print(rf$votes)

cat("\nVARIABLE IMPORTANCE\n")
rf.imp <- as.data.frame(importance(rf))
print(rf.imp)

print("\nSORTED VARIABLE IMPORTANCE\n")
print(head(rf.imp))
sort.field <- "MeanDecreaseAccuracy"
# sort.field <- "MeanDecreaseGini"
rf.imp.sort <- rf.imp[ order(rf.imp[[sort.field]], decreasing=TRUE) , ]
print(rf.imp.sort)

print("\nPREDICTIONS\n")
preds <- predict(rf, newdata=features, type='prob')
print(preds)

multiclass.logloss <- function(labels.prob, labels.int) {
    label.bin <- 1*(outer( rep(1, nrow(labels.prob)), c(1:9) ) == labels.int) 
    label.bin.prob <- as.matrix(label.bin * labels.prob)
    m <- rowSums(label.bin.prob)
    m.clip <- pmax(pmin(m, 1.0 - 1E-15), 1E-15)
    -mean(log(m.clip))
}

print(multiclass.logloss(preds, labels.int))

